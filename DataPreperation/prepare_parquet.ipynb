{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5e07bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "os.cpu_count() = 192\n",
      "SLURM_CPUS_PER_TASK = 16\n",
      "SLURM_JOB_CPUS_PER_NODE = 16\n"
     ]
    }
   ],
   "source": [
    "import os, glob\n",
    "import pandas as pd\n",
    "print(\"os.cpu_count() =\", os.cpu_count())\n",
    "print(\"SLURM_CPUS_PER_TASK =\", os.environ.get(\"SLURM_CPUS_PER_TASK\"))\n",
    "print(\"SLURM_JOB_CPUS_PER_NODE =\", os.environ.get(\"SLURM_JOB_CPUS_PER_NODE\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a26c9b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;34mgraphnet\u001b[0m [MainProcess] \u001b[33mWARNING \u001b[0m 2026-01-26 04:06:58 - <module> - `km3net` not available. Some functionality may be missing.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kbas/.local/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;34mgraphnet\u001b[0m [MainProcess] \u001b[33mWARNING \u001b[0m 2026-01-26 04:08:08 - <module> - `jammy_flows` not available. Normalizing Flow functionality is missing.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from graphnet.data.extractors.icecube.utilities.i3_filters import I3Filter\n",
    "from graphnet.utilities.imports import has_icecube_package\n",
    "\n",
    "if has_icecube_package():\n",
    "    from icecube import icetray  # noqa: F401\n",
    "\n",
    "\n",
    "class NonEmptyPulseSeriesI3Filter(I3Filter):\n",
    "    \"\"\"Drop frame if given PulseSeriesMap/Mask is empty (has 0 pulses).\"\"\"\n",
    "\n",
    "    def __init__(self, pulsemap_name: str = \"EventPulseSeries_nonoise\"):\n",
    "        super().__init__(name=__name__, class_name=self.__class__.__name__)\n",
    "        self._pulsemap_name = pulsemap_name\n",
    "\n",
    "    def _keep_frame(self, frame: \"icetray.I3Frame\") -> bool:\n",
    "        if not frame.Has(self._pulsemap_name):\n",
    "            return False\n",
    "\n",
    "        pm = frame[self._pulsemap_name]\n",
    "\n",
    "        # Handle MapMask vs Map\n",
    "        try:\n",
    "            if hasattr(pm, \"apply\"):\n",
    "                pm = pm.apply(frame)\n",
    "        except Exception:\n",
    "            # if apply fails for any reason, treat as not keep\n",
    "            return False\n",
    "\n",
    "        # Count total pulses across all OMKeys/PMTs\n",
    "        try:\n",
    "            total = 0\n",
    "            for _, series in pm.items():\n",
    "                total += len(series)\n",
    "                if total > 0:\n",
    "                    return True\n",
    "            return False\n",
    "        except Exception:\n",
    "            # fallback: if it behaves like a container\n",
    "            try:\n",
    "                return len(pm) > 0\n",
    "            except Exception:\n",
    "                return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21cd7c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, glob, re\n",
    "\n",
    "repo_root = os.path.abspath(\"..\")\n",
    "sys.path.append(repo_root)\n",
    "\n",
    "from MyClasses.reader import PONE_Reader\n",
    "from MyClasses.feature_extractor import I3FeatureExtractorPONE\n",
    "from MyClasses.truth_extractor import I3TruthExtractorPONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c2ac20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_GLOB = \"/project/def-nahee/kbas/POM_Response/*.i3.gz\"\n",
    "OUTDIR     = \"/project/def-nahee/kbas/POM_Response_Parquet\"\n",
    "GCD_RESCUE = \"/project/6008051/pone_simulation/GCD_Library/PONE_800mGrid.i3.gz\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5f8db12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_id_from_i3(path):\n",
    "    m = re.search(r\"batch_(\\d+)\\.i3\\.gz$\", os.path.basename(path))\n",
    "    return int(m.group(1)) if m else None\n",
    "\n",
    "def batch_ids_in_outdir(outdir):\n",
    "    # outdir içinde \"batch_1234\" geçen her şeyi tara\n",
    "    candidates = glob.glob(os.path.join(outdir, \"**\", \"*\"), recursive=True)\n",
    "    ids = set()\n",
    "    for p in candidates:\n",
    "        m = re.search(r\"batch_(\\d+)\", os.path.basename(p))\n",
    "        if m:\n",
    "            ids.add(int(m.group(1)))\n",
    "    return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91c80a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = sorted(glob.glob(INPUT_GLOB))\n",
    "done_ids  = batch_ids_in_outdir(OUTDIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b4fdb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "todo = []\n",
    "for f in all_files:\n",
    "    bid = batch_id_from_i3(f)\n",
    "    if bid is None:\n",
    "        continue\n",
    "    if bid not in done_ids:\n",
    "        todo.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8c1b0d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total i3: 9817\n",
      "Done batches: 0\n",
      "Todo i3: 9817\n",
      "First 5 todo: ['/project/def-nahee/kbas/POM_Response/pom_response_batch_000.i3.gz', '/project/def-nahee/kbas/POM_Response/pom_response_batch_001.i3.gz', '/project/def-nahee/kbas/POM_Response/pom_response_batch_002.i3.gz', '/project/def-nahee/kbas/POM_Response/pom_response_batch_003.i3.gz', '/project/def-nahee/kbas/POM_Response/pom_response_batch_004.i3.gz']\n"
     ]
    }
   ],
   "source": [
    "print(\"Total i3:\", len(all_files))\n",
    "print(\"Done batches:\", len(done_ids))\n",
    "print(\"Todo i3:\", len(todo))\n",
    "print(\"First 5 todo:\", todo[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8ee2a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphnet.data.dataconverter import DataConverter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1656c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphnet.data.writers import ParquetWriter\n",
    "from graphnet.data.extractors.icecube.utilities.i3_filters import NullSplitI3Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9442a9c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;34mgraphnet\u001b[0m [MainProcess] \u001b[32mINFO    \u001b[0m 2026-01-26 04:09:27 - NullSplitI3Filter.__init__ - Writing log to \u001b[1mlogs/graphnet_20260126-040927.log\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "reader = PONE_Reader(\n",
    "    gcd_rescue=GCD_RESCUE,\n",
    "    i3_filters=[NullSplitI3Filter(), NonEmptyPulseSeriesI3Filter(\"EventPulseSeries_nonoise\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "013c12a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "extractors = [\n",
    "    I3FeatureExtractorPONE(pulsemap=\"EventPulseSeries_nonoise\", name=\"features\", exclude=['pmt_area', 'rde', 'width', 'event_time', 'is_bright_dom', 'is_saturated_dom', 'is_errata_dom', 'is_bad_dom', 'hlc','awtd', 'dom_type']),\n",
    "    I3TruthExtractorPONE(mctree=\"I3MCTree_postprop\", name=\"truth\", exclude=['L7_oscNext_bool', 'L6_oscNext_bool',\n",
    "                                                               'L5_oscNext_bool', 'L4_oscNext_bool',\n",
    "                                                               'L3_oscNext_bool',\n",
    "                                                               'OnlineL2Filter_17','MuonFilter_13',\n",
    "                                                               'CascadeFilter_13','DeepCoreFilter_13', \n",
    "                                                                'dbang_decay_length', 'track_length', 'stopped_muon', 'energy_track', 'energy_cascade', 'inelasticity', 'is_starting'] ),\n",
    "\n",
    "]\n",
    "\n",
    "\n",
    "# included: pmt locs. check\n",
    "# include: truth per  pulse being noise or not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0cf8b65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = ParquetWriter(truth_table=\"truth\", index_column=\"event_no\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "38d0bda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = DataConverter(\n",
    "    file_reader=reader,\n",
    "    save_method=writer,  \n",
    "    extractors=extractors,\n",
    "    outdir=OUTDIR,\n",
    "    num_workers=16,  #4?\n",
    "    index_column=\"event_no\",\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3a142853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assuming list of directories.\n",
      "\u001b[1;34mgraphnet\u001b[0m [MainProcess] \u001b[32mINFO    \u001b[0m 2026-01-26 04:15:15 - DataConverter.__call__ - Starting pool of 16 workers to process9817 file(s)\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|\u001b[32m███████████████▎                                                                                     \u001b[0m| 1494/9817 [10:03<44:56,  3.09 file(s)/s]\u001b[0m"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'frame' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/usr/lib/python3.12/multiprocessing/pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n                    ^^^^^^^^^^^^^^^^^^^\n  File \"/project/6061446/kbas/pone_offline/graphnet/src/graphnet/data/dataconverter.py\", line 149, in _process_file\n    data = self._file_reader(file_path=file_path)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/project/6061446/kbas/Graphnet-Applications/MyClasses/reader.py\", line 94, in __call__\n    if self._skip_frame(frame):\n                        ^^^^^\nUnboundLocalError: cannot access local variable 'frame' where it is not associated with a value\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mconverter\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/project/def-nahee/kbas/POM_Response/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/project/6061446/kbas/pone_offline/graphnet/src/graphnet/data/dataconverter.py:106\u001b[0m, in \u001b[0;36mDataConverter.__call__\u001b[0;34m(self, input_dir)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;66;03m# Get the file reader to produce a list of input files\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;66;03m# in the directory\u001b[39;00m\n\u001b[1;32m    105\u001b[0m input_files \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file_reader\u001b[38;5;241m.\u001b[39mfind_files(path\u001b[38;5;241m=\u001b[39minput_dir)\n\u001b[0;32m--> 106\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_launch_jobs\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_files\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_files \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    108\u001b[0m     os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[1;32m    109\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_dir,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m input_files\n\u001b[1;32m    113\u001b[0m ]\n",
      "File \u001b[0;32m/project/6061446/kbas/pone_offline/graphnet/src/graphnet/data/dataconverter.py:132\u001b[0m, in \u001b[0;36mDataConverter._launch_jobs\u001b[0;34m(self, input_files)\u001b[0m\n\u001b[1;32m    129\u001b[0m map_fn, pool \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_map_function(nb_files\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(input_files))\n\u001b[1;32m    131\u001b[0m \u001b[38;5;66;03m# Iterate over files\u001b[39;00m\n\u001b[0;32m--> 132\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmap_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_files\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m file(s)\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolour\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgreen\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdebug\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprocessing file.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_shared_variables(pool)\n",
      "File \u001b[0;32m/usr/lib/python3.12/multiprocessing/pool.py:873\u001b[0m, in \u001b[0;36mIMapIterator.next\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m    872\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m value\n\u001b[0;32m--> 873\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m value\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: cannot access local variable 'frame' where it is not associated with a value"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[32m███████████████████████████████████████████████████████████████████████████████████████████████████\u001b[0m| 9817/9817 [1:06:55<00:00,  2.44 file(s)/s]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "converter(input_dir=\"/project/def-nahee/kbas/POM_Response/\")\n",
    "# used:\n",
    "# salloc --time=5:30:00 --account=def-nahee --ntasks=1 --cpus-per-task=16 --mem=128G \n",
    "# less than 5 hours would also work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2546f55f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE: /project/def-nahee/kbas/POM_Response_Parquet\n"
     ]
    }
   ],
   "source": [
    "print(\"DONE:\", OUTDIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "59d0eeba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT i3 files: 9817\n",
      "truth parquet: 9787\n",
      "features parquet: 9787\n",
      "both exist: 9787\n",
      "missing any: 30\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_file</th>\n",
       "      <th>stem</th>\n",
       "      <th>truth_exists</th>\n",
       "      <th>features_exists</th>\n",
       "      <th>both_exist</th>\n",
       "      <th>missing_any</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/project/def-nahee/kbas/POM_Response/pom_respo...</td>\n",
       "      <td>pom_response_batch_000</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/project/def-nahee/kbas/POM_Response/pom_respo...</td>\n",
       "      <td>pom_response_batch_001</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/project/def-nahee/kbas/POM_Response/pom_respo...</td>\n",
       "      <td>pom_response_batch_002</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/project/def-nahee/kbas/POM_Response/pom_respo...</td>\n",
       "      <td>pom_response_batch_003</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/project/def-nahee/kbas/POM_Response/pom_respo...</td>\n",
       "      <td>pom_response_batch_004</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9812</th>\n",
       "      <td>/project/def-nahee/kbas/POM_Response/pom_respo...</td>\n",
       "      <td>pom_response_batch_9995</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9813</th>\n",
       "      <td>/project/def-nahee/kbas/POM_Response/pom_respo...</td>\n",
       "      <td>pom_response_batch_9996</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9814</th>\n",
       "      <td>/project/def-nahee/kbas/POM_Response/pom_respo...</td>\n",
       "      <td>pom_response_batch_9997</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9815</th>\n",
       "      <td>/project/def-nahee/kbas/POM_Response/pom_respo...</td>\n",
       "      <td>pom_response_batch_9998</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9816</th>\n",
       "      <td>/project/def-nahee/kbas/POM_Response/pom_respo...</td>\n",
       "      <td>pom_response_batch_9999</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9817 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             input_file  \\\n",
       "0     /project/def-nahee/kbas/POM_Response/pom_respo...   \n",
       "1     /project/def-nahee/kbas/POM_Response/pom_respo...   \n",
       "2     /project/def-nahee/kbas/POM_Response/pom_respo...   \n",
       "3     /project/def-nahee/kbas/POM_Response/pom_respo...   \n",
       "4     /project/def-nahee/kbas/POM_Response/pom_respo...   \n",
       "...                                                 ...   \n",
       "9812  /project/def-nahee/kbas/POM_Response/pom_respo...   \n",
       "9813  /project/def-nahee/kbas/POM_Response/pom_respo...   \n",
       "9814  /project/def-nahee/kbas/POM_Response/pom_respo...   \n",
       "9815  /project/def-nahee/kbas/POM_Response/pom_respo...   \n",
       "9816  /project/def-nahee/kbas/POM_Response/pom_respo...   \n",
       "\n",
       "                         stem  truth_exists  features_exists  both_exist  \\\n",
       "0      pom_response_batch_000          True             True        True   \n",
       "1      pom_response_batch_001          True             True        True   \n",
       "2      pom_response_batch_002          True             True        True   \n",
       "3      pom_response_batch_003          True             True        True   \n",
       "4      pom_response_batch_004          True             True        True   \n",
       "...                       ...           ...              ...         ...   \n",
       "9812  pom_response_batch_9995          True             True        True   \n",
       "9813  pom_response_batch_9996          True             True        True   \n",
       "9814  pom_response_batch_9997          True             True        True   \n",
       "9815  pom_response_batch_9998          True             True        True   \n",
       "9816  pom_response_batch_9999          True             True        True   \n",
       "\n",
       "      missing_any  \n",
       "0           False  \n",
       "1           False  \n",
       "2           False  \n",
       "3           False  \n",
       "4           False  \n",
       "...           ...  \n",
       "9812        False  \n",
       "9813        False  \n",
       "9814        False  \n",
       "9815        False  \n",
       "9816        False  \n",
       "\n",
       "[9817 rows x 6 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INPUT_DIR = \"/project/def-nahee/kbas/POM_Response/\"\n",
    "OUTDIR    = \"/project/def-nahee/kbas/POM_Response_Parquet\"\n",
    "\n",
    "in_files = sorted(glob.glob(os.path.join(INPUT_DIR, \"**\", \"*.i3.gz\"), recursive=True))\n",
    "in_files += sorted(glob.glob(os.path.join(INPUT_DIR, \"**\", \"*.i3\"), recursive=True))\n",
    "\n",
    "def stem_from_i3(path: str) -> str:\n",
    "    base = os.path.basename(path)\n",
    "    if base.endswith(\".i3.gz\"):\n",
    "        return base[:-len(\".i3.gz\")]\n",
    "    if base.endswith(\".i3\"):\n",
    "        return base[:-len(\".i3\")]\n",
    "    return os.path.splitext(base)[0]\n",
    "\n",
    "in_stems = [stem_from_i3(f) for f in in_files]\n",
    "\n",
    "truth_dir = os.path.join(OUTDIR, \"truth\")\n",
    "feat_dir  = os.path.join(OUTDIR, \"features\")\n",
    "\n",
    "truth_files = sorted(glob.glob(os.path.join(truth_dir, \"*_truth.parquet\")))\n",
    "feat_files  = sorted(glob.glob(os.path.join(feat_dir, \"*_features.parquet\")))\n",
    "\n",
    "def stem_from_parquet(path: str, suffix: str) -> str:\n",
    "    base = os.path.basename(path)\n",
    "    return base[:-len(suffix)] if base.endswith(suffix) else os.path.splitext(base)[0]\n",
    "\n",
    "truth_stems = set(stem_from_parquet(p, \"_truth.parquet\") for p in truth_files)\n",
    "feat_stems  = set(stem_from_parquet(p, \"_features.parquet\") for p in feat_files)\n",
    "\n",
    "rows = []\n",
    "for f, s in zip(in_files, in_stems):\n",
    "    rows.append({\n",
    "        \"input_file\": f,\n",
    "        \"stem\": s,\n",
    "        \"truth_exists\": s in truth_stems,\n",
    "        \"features_exists\": s in feat_stems,\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df[\"both_exist\"] = df[\"truth_exists\"] & df[\"features_exists\"]\n",
    "df[\"missing_any\"] = ~(df[\"both_exist\"])\n",
    "\n",
    "print(\"INPUT i3 files:\", len(df))\n",
    "print(\"truth parquet:\", len(truth_stems))\n",
    "print(\"features parquet:\", len(feat_stems))\n",
    "print(\"both exist:\", int(df[\"both_exist\"].sum()))\n",
    "print(\"missing any:\", int(df[\"missing_any\"].sum()))\n",
    "\n",
    "missing = df[df[\"missing_any\"]].copy()\n",
    "missing.to_csv(\"missing_conversions.csv\", index=False)\n",
    "\n",
    "with open(\"missing_input_files.txt\", \"w\") as w:\n",
    "    for p in missing[\"input_file\"]:\n",
    "        w.write(p + \"\\n\")\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b0cf44",
   "metadata": {},
   "source": [
    "I could not create POM Response (GZ) for some (around 400) batches. (Or maybe I created wrongly). Here, they must be excluded. Additionally, here, there may be some new missing batches during the transition GZ -> Parquet (around 30 batches). However, I still continue and merge the files. Later I can handle missing files and re-create the merged file again."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f132393",
   "metadata": {},
   "source": [
    "### Create the merged file (later I will split into train/val/test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f991b78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "MERGED_DIR = os.path.join(OUTDIR, \"merged\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a542fbea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/project/def-nahee/kbas/POM_Response_Parquet/merged'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MERGED_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bcf00c1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;34mgraphnet\u001b[0m [MainProcess] \u001b[32mINFO    \u001b[0m 2026-01-26 05:32:39 - ParquetWriter.run_code - Processing 394 batches using 16 cores.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[32m███████████████████████████████████████████████████████████████████████████████████████████████████████\u001b[0m| 394/394 [03:00<00:00,  2.18shard(s)/s]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "writer.merge_files(\n",
    "    files=[],\n",
    "    output_dir=MERGED_DIR,\n",
    "    events_per_batch=1024,\n",
    "    num_workers=16,\n",
    ")\n",
    "\n",
    "#  this could handle: \n",
    "#  salloc --time=2:30:00 --account=def-nahee --ntasks=1 --cpus-per-task=16 --mem=128G "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f6f7e2c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch_id</th>\n",
       "      <th>truth_rows</th>\n",
       "      <th>truth_unique_events</th>\n",
       "      <th>features_rows</th>\n",
       "      <th>features_unique_events</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1024</td>\n",
       "      <td>1024</td>\n",
       "      <td>152763</td>\n",
       "      <td>1024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>1024</td>\n",
       "      <td>148463</td>\n",
       "      <td>1024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1024</td>\n",
       "      <td>1024</td>\n",
       "      <td>144144</td>\n",
       "      <td>1024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1024</td>\n",
       "      <td>1024</td>\n",
       "      <td>178179</td>\n",
       "      <td>1024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1024</td>\n",
       "      <td>1024</td>\n",
       "      <td>146573</td>\n",
       "      <td>1024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>389</td>\n",
       "      <td>1024</td>\n",
       "      <td>1024</td>\n",
       "      <td>145768</td>\n",
       "      <td>1024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>390</td>\n",
       "      <td>1024</td>\n",
       "      <td>1024</td>\n",
       "      <td>143678</td>\n",
       "      <td>1024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>391</td>\n",
       "      <td>1024</td>\n",
       "      <td>1024</td>\n",
       "      <td>185765</td>\n",
       "      <td>1024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>392</td>\n",
       "      <td>1024</td>\n",
       "      <td>1024</td>\n",
       "      <td>141762</td>\n",
       "      <td>1024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>393</td>\n",
       "      <td>482</td>\n",
       "      <td>482</td>\n",
       "      <td>58749</td>\n",
       "      <td>482</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>394 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     batch_id  truth_rows  truth_unique_events  features_rows  \\\n",
       "0           0        1024                 1024         152763   \n",
       "1           1        1024                 1024         148463   \n",
       "2           2        1024                 1024         144144   \n",
       "3           3        1024                 1024         178179   \n",
       "4           4        1024                 1024         146573   \n",
       "..        ...         ...                  ...            ...   \n",
       "389       389        1024                 1024         145768   \n",
       "390       390        1024                 1024         143678   \n",
       "391       391        1024                 1024         185765   \n",
       "392       392        1024                 1024         141762   \n",
       "393       393         482                  482          58749   \n",
       "\n",
       "     features_unique_events  \n",
       "0                      1024  \n",
       "1                      1024  \n",
       "2                      1024  \n",
       "3                      1024  \n",
       "4                      1024  \n",
       "..                      ...  \n",
       "389                    1024  \n",
       "390                    1024  \n",
       "391                    1024  \n",
       "392                    1024  \n",
       "393                     482  \n",
       "\n",
       "[394 rows x 5 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "\n",
    "MERGED_DIR = Path(MERGED_DIR)   # senin OUTDIR/merged\n",
    "\n",
    "def pick_event_col(parquet_path: Path) -> str:\n",
    "    cols = pl.read_parquet(parquet_path, n_rows=0).columns\n",
    "    if \"event_no\" in cols:\n",
    "        return \"event_no\"\n",
    "    if \"__index_level_0__\" in cols:   # pandas index bazen böyle kaydediyor\n",
    "        return \"__index_level_0__\"\n",
    "    # fallback: ilk kolon (en azından unique sayısı alabilelim)\n",
    "    return cols[0]\n",
    "\n",
    "def count_rows(parquet_path: Path) -> int:\n",
    "    return int(pl.scan_parquet(parquet_path).select(pl.len()).collect().item())\n",
    "\n",
    "def count_unique_events(parquet_path: Path) -> int:\n",
    "    col = pick_event_col(parquet_path)\n",
    "    return int(pl.scan_parquet(parquet_path).select(pl.col(col).n_unique()).collect().item())\n",
    "\n",
    "# batch id’leri (truth_123.parquet gibi)\n",
    "truth_dir = MERGED_DIR / \"truth\"\n",
    "feat_dir  = MERGED_DIR / \"features\"\n",
    "\n",
    "pat_truth = re.compile(r\"^truth_(\\d+)\\.parquet$\")\n",
    "pat_feat  = re.compile(r\"^features_(\\d+)\\.parquet$\")\n",
    "\n",
    "truth_files = {int(pat_truth.match(p.name).group(1)): p for p in truth_dir.glob(\"truth_*.parquet\") if pat_truth.match(p.name)}\n",
    "feat_files  = {int(pat_feat.match(p.name).group(1)): p for p in feat_dir.glob(\"features_*.parquet\") if pat_feat.match(p.name)}\n",
    "\n",
    "batch_ids = sorted(set(truth_files) & set(feat_files))\n",
    "\n",
    "rows = []\n",
    "for bid in batch_ids:\n",
    "    tf = truth_files[bid]\n",
    "    ff = feat_files[bid]\n",
    "    rows.append({\n",
    "        \"batch_id\": bid,\n",
    "        \"truth_rows\": count_rows(tf),\n",
    "        \"truth_unique_events\": count_unique_events(tf),\n",
    "        \"features_rows\": count_rows(ff),\n",
    "        \"features_unique_events\": count_unique_events(ff),\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(rows).sort_values(\"batch_id\").reset_index(drop=True)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e7681927",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "402914"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# there are \n",
    "393*1024+482\n",
    "# events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e2f211a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moved: /project/def-nahee/kbas/POM_Response_Parquet/merged -> /project/def-nahee/kbas/POM_Response_Parquet/merged_raw\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os, re, random, shutil, json\n",
    "\n",
    "MERGED_DIR = Path(MERGED_DIR)          # .../merged (şu anki)\n",
    "MERGED_RAW = MERGED_DIR.parent / \"merged_raw\"\n",
    "\n",
    "# 1) merged -> merged_raw (eğer daha önce yapılmadıysa)\n",
    "if not MERGED_RAW.exists():\n",
    "    os.rename(MERGED_DIR, MERGED_RAW)\n",
    "    print(\"moved:\", MERGED_DIR, \"->\", MERGED_RAW)\n",
    "else:\n",
    "    print(\"merged_raw already exists:\", MERGED_RAW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "822a3946",
   "metadata": {},
   "outputs": [],
   "source": [
    "truth_dir = MERGED_RAW / \"truth\"\n",
    "feat_dir  = MERGED_RAW / \"features\"\n",
    "\n",
    "pat = re.compile(r\"^truth_(\\d+)\\.parquet$\")\n",
    "batch_ids = sorted(int(pat.match(p.name).group(1)) for p in truth_dir.glob(\"truth_*.parquet\") if pat.match(p.name))\n",
    "\n",
    "last_batch = max(batch_ids)            # 482'lik batch bu olmalı\n",
    "main_batches = [b for b in batch_ids if b != last_batch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "64bae2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "rng = random.Random(seed)\n",
    "rng.shuffle(main_batches)\n",
    "\n",
    "n = len(main_batches)\n",
    "n_train = int(0.8 * n)\n",
    "n_val   = int(0.1 * n)\n",
    "\n",
    "splits = {\n",
    "    \"train\": main_batches[:n_train],\n",
    "    \"val\":   main_batches[n_train:n_train+n_val],\n",
    "    \"test\":  main_batches[n_train+n_val:] + [last_batch],  # <-- last batch burada\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c50dcff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def link_or_copy(src: Path, dst: Path):\n",
    "    dst.parent.mkdir(parents=True, exist_ok=True)\n",
    "    if dst.exists():\n",
    "        return\n",
    "    try:\n",
    "        os.link(src, dst)          # hardlink (tercih)\n",
    "    except Exception:\n",
    "        try:\n",
    "            os.symlink(src, dst)   # symlink\n",
    "        except Exception:\n",
    "            shutil.copy2(src, dst) # fallback copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "10b77a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done: /project/def-nahee/kbas/POM_Response_Parquet/merged\n",
      "{'train': 314, 'val': 39, 'test': 41}\n"
     ]
    }
   ],
   "source": [
    "NEW_MERGED = MERGED_RAW.parent / \"merged\"\n",
    "tables = [\"truth\", \"features\"]\n",
    "\n",
    "for split_name, ids in splits.items():\n",
    "    for table in tables:\n",
    "        for bid in ids:\n",
    "            src = (MERGED_RAW / table / f\"{table}_{bid}.parquet\")\n",
    "            dst = (NEW_MERGED / split_name / table / src.name)\n",
    "            if src.exists():\n",
    "                link_or_copy(src, dst)\n",
    "\n",
    "# manifest kaydet\n",
    "manifest = {\n",
    "    \"seed\": seed,\n",
    "    \"fractions\": {\"train\": 0.8, \"val\": 0.1, \"test\": 0.1},\n",
    "    \"last_batch_forced_to_test\": int(last_batch),\n",
    "    \"counts_in_batches\": {k: len(v) for k, v in splits.items()},\n",
    "    \"splits\": splits,\n",
    "}\n",
    "\n",
    "with open(NEW_MERGED / \"split_manifest.json\", \"w\") as f:\n",
    "    json.dump(manifest, f, indent=2)\n",
    "\n",
    "print(\"done:\", NEW_MERGED)\n",
    "print({k: len(v) for k, v in splits.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5a449c70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "394"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "314+39+41 # total number of batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adea13cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
