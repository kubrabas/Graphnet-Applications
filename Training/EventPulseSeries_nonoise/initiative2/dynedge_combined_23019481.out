===== SLURM INFO =====
JOBID: 23019481
NODELIST: fc10504
CPUS_PER_TASK: 12
GPUS_ON_NODE: 1
SUBMIT_DIR: /project/6061446/kbas/Graphnet-Applications/Training/EventPulseSeries_nonoise/initiative2
======================
===== SCONTROL (Req/Alloc) =====
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=fc10504
   ReqTRES=cpu=12,mem=48G,node=1,billing=12200,gres/gpu=1,gres/gpu:h100=1
   AllocTRES=cpu=12,mem=48G,node=1,billing=12200,gres/gpu=1,gres/gpu:h100=1
================================
The following modules were not unloaded:
  (Use "module --force purge" to unload all):

  1) CCconfig        6)  ucx/1.14.1         11) flexiblas/3.3.1
  2) gentoo/2023     7)  libfabric/1.18.0   12) aocl-blas/5.1
  3) gcccore/.12.3   8)  pmix/4.2.4         13) aocl-lapack/5.1
  4) gcc/12.3        9)  ucc/1.2.0          14) StdEnv/2023
  5) hwloc/2.9.1     10) openmpi/4.1.5
===== ENV SETUP =====
PWD: /project/def-nahee/kbas/pone_offline
Activating venv: /project/def-nahee/kbas/pone_offline/graphnet_env/bin/activate
Python: /project/6061446/kbas/pone_offline/graphnet_env/bin/python3
sys.executable = /project/6061446/kbas/pone_offline/graphnet_env/bin/python3
torch: 2.6.0
cuda available: True
cuda device: NVIDIA H100 80GB HBM3
===== GPU INFO =====
Mon Feb 16 03:20:09 2026       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 580.65.06              Driver Version: 580.65.06      CUDA Version: 13.0     |
+-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA H100 80GB HBM3          On  |   00000000:0C:00.0 Off |                    0 |
| N/A   23C    P0             68W /  700W |       0MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+

+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
====================
===== RUN =====

========== CONFIG ==========
seed: 20260202
train_path: /project/def-nahee/kbas/POM_Response_Parquet/merged/train_reindexed
val_path: /project/def-nahee/kbas/POM_Response_Parquet/merged/val_reindexed
test_path: /project/def-nahee/kbas/POM_Response_Parquet/merged/test_reindexed
pulsemaps: features
truth_table: truth
features: ('pmt_x', 'pmt_y', 'pmt_z', 'dom_time', 'charge')
truth_all: ('azimuth', 'zenith', 'energy')
batch_size: 256
num_workers: 8
multiprocessing_context: spawn
persistent_workers: True
pin_memory: True
max_epochs: 3
early_stopping_patience: 5
base_lr: 1e-05
peak_lr: 0.001
accumulate_grad_batches: 4
nb_neighbours: 8
global_pooling_schemes: ('min', 'max', 'mean', 'sum')
add_global_variables_after_pooling: True
add_norm_layer: False
skip_readout: False
transform_support: (10.0, 100000000.0)
save_dir: /project/6061446/kbas/Graphnet-Applications/Training/EventPulseSeries_nonoise/initiative2
metrics_name: metrics.csv
test_csv_name: test_predictions.csv
resources_and_time_csv_name: resources_and_time.csv
early_stopping_monitor_energy: val_loss
early_stopping_monitor_angle: val_loss
early_stopping_mode: min
val_metrics_max_batches: None
============================

[Data] Building data_representation (KNNGraph + robust scaling)
[1;34mgraphnet[0m [MainProcess] [32mINFO    [0m 2026-02-16 03:23:12 - PONE.__init__ - Writing log to [1mlogs/graphnet_20260216-032312.log[0m
[Data] Creating ParquetDataset(s)
[Data] Creating DataLoader(s)
[Data] len(train_loader) = 1256 batches/epoch (drop_last=True)
[Data] len(val_loader)   = 156 batches/epoch
[Data] len(test_loader)  = 162 batches
[Sanity] azimuth range: 0.079..6.266
[Sanity] zenith  range: 0.108..3.077
[Sanity] energy  range: 1.002e+02..2.989e+06
[rank: 0] Seed set to 20260202

[Run=energy] torch.cuda.is_available() = True
[Run=energy] GPU = NVIDIA H100 80GB HBM3
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
/project/6061446/kbas/pone_offline/graphnet_env/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:76: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default
You are using a CUDA device ('NVIDIA H100 80GB HBM3') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name                 | Type       | Params | Mode 
------------------------------------------------------------
0 | _tasks               | ModuleList | 129    | train
1 | _data_representation | KNNGraph   | 0      | train
2 | backbone             | DynEdge    | 1.4 M  | train
------------------------------------------------------------
1.4 M     Trainable params
0         Non-trainable params
1.4 M     Total params
5.501     Total estimated model params size (MB)
36        Modules in train mode
0         Modules in eval mode
SLURM auto-requeueing enabled. Setting signal handlers.
Metric val_loss improved. New best score: 0.139 | epoch: 0
[1;34mgraphnet[0m [MainProcess] [32mINFO    [0m 2026-02-16 03:45:59 - StandardModel.save_state_dict - Model state_dict saved to /project/6061446/kbas/Graphnet-Applications/Training/EventPulseSeries_nonoise/initiative2/energy/best_model.pth[0m
Metric val_loss improved by 0.019 >= min_delta = 0.0. New best score: 0.120 | epoch: 1
[1;34mgraphnet[0m [MainProcess] [32mINFO    [0m 2026-02-16 04:05:39 - StandardModel.save_state_dict - Model state_dict saved to /project/6061446/kbas/Graphnet-Applications/Training/EventPulseSeries_nonoise/initiative2/energy/best_model.pth[0m
Metric val_loss improved by 0.014 >= min_delta = 0.0. New best score: 0.105 | epoch: 2
[1;34mgraphnet[0m [MainProcess] [32mINFO    [0m 2026-02-16 04:25:10 - StandardModel.save_state_dict - Model state_dict saved to /project/6061446/kbas/Graphnet-Applications/Training/EventPulseSeries_nonoise/initiative2/energy/best_model.pth[0m
`Trainer.fit` stopped: `max_epochs=3` reached.
[Resources] Wrote /project/6061446/kbas/Graphnet-Applications/Training/EventPulseSeries_nonoise/initiative2/energy/resources_and_time.csv | last_epoch=2 | total=61.31 min
[Run=energy] best_model: /project/6061446/kbas/Graphnet-Applications/Training/EventPulseSeries_nonoise/initiative2/energy/best_model.pth
[Run=energy] config:     /project/6061446/kbas/Graphnet-Applications/Training/EventPulseSeries_nonoise/initiative2/energy/config.yml
[Run=energy] metrics:    /project/6061446/kbas/Graphnet-Applications/Training/EventPulseSeries_nonoise/initiative2/energy/metrics.csv
[Test=energy] Loaded best weights: /project/6061446/kbas/Graphnet-Applications/Training/EventPulseSeries_nonoise/initiative2/energy/best_model.pth
[Test=energy] Wrote: /project/6061446/kbas/Graphnet-Applications/Training/EventPulseSeries_nonoise/initiative2/energy/test_predictions.csv | rows=41311
[Test=energy] residual_log10: p16=-0.4052, p50=0.0339, p84=0.3593, W=0.3822 | mae=0.3458 rmse=0.5075
[rank: 0] Seed set to 20260202

[Run=azimuth] torch.cuda.is_available() = True
[Run=azimuth] GPU = NVIDIA H100 80GB HBM3
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name                 | Type       | Params | Mode 
------------------------------------------------------------
0 | _tasks               | ModuleList | 258    | train
1 | _data_representation | KNNGraph   | 0      | eval 
2 | backbone             | DynEdge    | 1.4 M  | train
------------------------------------------------------------
1.4 M     Trainable params
0         Non-trainable params
1.4 M     Total params
5.502     Total estimated model params size (MB)
32        Modules in train mode
4         Modules in eval mode
SLURM auto-requeueing enabled. Setting signal handlers.
/project/6061446/kbas/pone_offline/graphnet_env/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:527: Found 4 module(s) in eval mode at the start of training. This may lead to unexpected behavior during training. If this is intentional, you can ignore this warning.
Metric val_loss improved. New best score: -0.094 | epoch: 0
[1;34mgraphnet[0m [MainProcess] [32mINFO    [0m 2026-02-16 05:06:58 - StandardModel.save_state_dict - Model state_dict saved to /project/6061446/kbas/Graphnet-Applications/Training/EventPulseSeries_nonoise/initiative2/azimuth/best_model.pth[0m
Metric val_loss improved by 0.211 >= min_delta = 0.0. New best score: -0.306 | epoch: 1
[1;34mgraphnet[0m [MainProcess] [32mINFO    [0m 2026-02-16 05:26:24 - StandardModel.save_state_dict - Model state_dict saved to /project/6061446/kbas/Graphnet-Applications/Training/EventPulseSeries_nonoise/initiative2/azimuth/best_model.pth[0m
Metric val_loss improved by 0.075 >= min_delta = 0.0. New best score: -0.381 | epoch: 2
[1;34mgraphnet[0m [MainProcess] [32mINFO    [0m 2026-02-16 05:45:53 - StandardModel.save_state_dict - Model state_dict saved to /project/6061446/kbas/Graphnet-Applications/Training/EventPulseSeries_nonoise/initiative2/azimuth/best_model.pth[0m
`Trainer.fit` stopped: `max_epochs=3` reached.
[Resources] Wrote /project/6061446/kbas/Graphnet-Applications/Training/EventPulseSeries_nonoise/initiative2/azimuth/resources_and_time.csv | last_epoch=2 | total=62.01 min
[Run=azimuth] best_model: /project/6061446/kbas/Graphnet-Applications/Training/EventPulseSeries_nonoise/initiative2/azimuth/best_model.pth
[Run=azimuth] config:     /project/6061446/kbas/Graphnet-Applications/Training/EventPulseSeries_nonoise/initiative2/azimuth/config.yml
[Run=azimuth] metrics:    /project/6061446/kbas/Graphnet-Applications/Training/EventPulseSeries_nonoise/initiative2/azimuth/metrics.csv
[Test=azimuth] Loaded best weights: /project/6061446/kbas/Graphnet-Applications/Training/EventPulseSeries_nonoise/initiative2/azimuth/best_model.pth
[Test=azimuth] Wrote: /project/6061446/kbas/Graphnet-Applications/Training/EventPulseSeries_nonoise/initiative2/azimuth/test_predictions.csv | rows=41311
[Test=azimuth] residual_deg (signed): p16=-7.725, p50=0.077, p84=7.677 | W_deg=7.701 | kappa_mean=54.396
[rank: 0] Seed set to 20260202

[Run=zenith] torch.cuda.is_available() = True
[Run=zenith] GPU = NVIDIA H100 80GB HBM3
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name                 | Type       | Params | Mode 
------------------------------------------------------------
0 | _tasks               | ModuleList | 258    | train
1 | _data_representation | KNNGraph   | 0      | eval 
2 | backbone             | DynEdge    | 1.4 M  | train
------------------------------------------------------------
1.4 M     Trainable params
0         Non-trainable params
1.4 M     Total params
5.502     Total estimated model params size (MB)
32        Modules in train mode
4         Modules in eval mode
SLURM auto-requeueing enabled. Setting signal handlers.
/project/6061446/kbas/pone_offline/graphnet_env/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:527: Found 4 module(s) in eval mode at the start of training. This may lead to unexpected behavior during training. If this is intentional, you can ignore this warning.
