{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d39d8398-03d8-4a93-97e8-e48eb3ead26b",
   "metadata": {},
   "source": [
    "# EdgeConv (PyTorch Geometric) \n",
    "\n",
    "EdgeConv updates each node by aggregating messages from its neighbors:\n",
    "\n",
    "$$\n",
    "x'_i = \\operatorname{AGG}_{j \\in \\mathcal{N}(i)} \\; h_\\theta\\!\\left(\\left[x_i,\\; x_j - x_i\\right]\\right)\n",
    "$$\n",
    "\n",
    "- $x_i$: feature vector of node $i$  \n",
    "- $\\mathcal{N}(i)$: neighbors of node $i$ (defined by `edge_index`)  \n",
    "- $\\left[x_i,\\; x_j - x_i\\right]$: **concatenation** (the node itself + relative difference to a neighbor)  \n",
    "- $h_\\theta(\\cdot)$: a learnable function, typically an **MLP**  \n",
    "- $\\operatorname{AGG}$: neighborhood aggregation (e.g., $\\max$, $\\sum$, mean)\n",
    "\n",
    "If the aggregation is **sum**, this becomes:\n",
    "\n",
    "$$\n",
    "x'_i = \\sum_{j \\in \\mathcal{N}(i)} h_\\theta\\!\\left(\\left[x_i,\\; x_j - x_i\\right]\\right)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4ebb77-108f-4181-8020-13503a6288a5",
   "metadata": {},
   "source": [
    "### `edge_index` with kNN (PyG)\n",
    "\n",
    "EdgeConv needs a graph structure: `edge_index` (who is connected to whom).  \n",
    "A common way to build this graph is **k-nearest neighbors (kNN)**:\n",
    "\n",
    "- We choose a feature space for distance (PMT/DOM positions in our case).\n",
    "- For each node, we find its **k nearest neighbors** within the same event (using `batch`).\n",
    "- The result is `edge_index` with shape **[2, E]**, where each column is one directed edge `(source -> target)`. (here, source is the neighbour, target is the node. This is directed arrow)\n",
    "\n",
    "Key idea:\n",
    "- `x_knn = x[:, features_subset]` decides **which features** are used for the distance computation.\n",
    "- `batch` prevents connecting nodes from different events.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1fe2e8-7ec7-4ef6-8c84-1fe4d38bba6a",
   "metadata": {},
   "source": [
    "### Learnable Function Example: MLP\n",
    "\n",
    "EdgeConv is a **message passing** layer. It needs a learnable function to turn a pair\n",
    "of nodes (a node and one of its neighbors) into a **message**.  \n",
    "That learnable function is the **MLP** we pass in here.\n",
    "\n",
    "For each directed edge (neighbor relation) $j \\rightarrow i$:\n",
    "\n",
    "1. Take the target node features $x_i$  \n",
    "2. Take the relative difference to the neighbor $x_j - x_i$  \n",
    "3. Concatenate them to form the MLP input:\n",
    "   $$\n",
    "   z_{ij} = \\left[x_i,\\; x_j - x_i\\right]\n",
    "   $$\n",
    "   after the concatenation, the feature number doubles.\n",
    "5. Compute a message with the MLP:\n",
    "   $$\n",
    "   m_{ij} = \\mathrm{MLP}(z_{ij})\n",
    "   $$\n",
    "6. Aggregate all neighbor messages (e.g. max/sum/mean) to update the node:\n",
    "   $$\n",
    "   x'_i = \\operatorname{AGG}_{j \\in \\mathcal{N}(i)} m_{ij}\n",
    "   $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea49ecc9-4aa2-40d3-9a85-52f3afe83dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.nn.pool import knn_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9416d5a5-388f-4441-9c59-c3285e245723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Fake mini-batch: 2 events ---\n",
    "# Event 0 has 4 nodes, Event 1 has 6 nodes -> total N=10\n",
    "n0, n1 = 4, 6\n",
    "N = n0 + n1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "436f1546-8a5f-4359-ad8c-558201a38564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch[i] = event_id of node i\n",
    "batch = torch.tensor([0]*n0 + [1]*n1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87aed3aa-c684-428d-98f1-7c499ccb58cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33b7310e-8d59-4f41-85b7-96b7100c8deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape: torch.Size([10, 8])\n",
      "batch shape: torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "# Node features: let's create [N, 8] : pmt_x, pmt_y, pmt_z, pmt_i, pmt_j, pmt_k, q, t (i, j, k: angle; x, y, z: position)\n",
    "# First 3 features = \"position\" (used for kNN)\n",
    "pos = torch.randn(N, 3) * 5.0\n",
    "other_5 = torch.randn(N, 5)\n",
    "x = torch.cat([pos, other_5], dim=1)\n",
    "\n",
    "print(\"x shape:\", x.shape)         # [N, 8]\n",
    "print(\"batch shape:\", batch.shape) # [N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db83c0e6-36dc-4da9-a293-f67e18770210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -0.1572,  -1.1941, -10.0239,  -0.5515,  -0.2864,   1.2036,   0.2426,\n",
       "           0.3425],\n",
       "        [  6.5740,   3.3514,   3.4227,   2.1173,  -0.5528,  -0.0833,   0.5151,\n",
       "           0.0869],\n",
       "        [  3.7905,  -6.8601,  -0.0668,  -0.9295,   1.4618,  -0.7746,   0.1659,\n",
       "           0.3784],\n",
       "        [  1.5559,  -2.7138,  -5.7097,  -0.6423,   1.3420,  -0.7579,   1.2664,\n",
       "          -0.3835],\n",
       "        [ -3.6128,   1.0768,   5.0375,  -0.6368,   0.1879,  -0.9061,  -0.1070,\n",
       "          -0.6018],\n",
       "        [ -6.1118,   8.2047,  -6.6751,  -2.0629,  -0.2136,   0.1861,  -0.3162,\n",
       "           0.2089],\n",
       "        [ -0.9872,   2.5065,  -6.6366,  -3.0602,   0.6658,   0.2832,   0.2519,\n",
       "          -1.9083],\n",
       "        [ -4.6310,  -0.3009,   5.3977,   0.9575,  -1.7559,  -0.1788,  -0.5045,\n",
       "           1.0550],\n",
       "        [ -0.0400,  -3.3818,   4.0182,   1.8160,   0.0778,  -0.5094,  -0.0233,\n",
       "           0.2756],\n",
       "        [ -4.3483,   0.6645,   8.6566,   0.0539,   0.7440,   0.1583,  -1.3908,\n",
       "          -0.5963]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9bc42a7-7908-4ba8-9efc-7856a6c92574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Build edges with kNN using only the first 3 features (pos) ---\n",
    "k = 3\n",
    "edge_index = knn_graph(\n",
    "    x=x[:, :3],      # use position only for distance\n",
    "    k=k,\n",
    "    batch=batch,\n",
    "    loop=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e57b17dc-ef05-400f-94f8-a23fef7d6581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edge_index shape: torch.Size([2, 30])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"edge_index shape:\", edge_index.shape)  # [2, N*k] (directed edges)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ee6a55d-6006-4e9d-aa4e-e6be0d4c4e04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3, 2, 1, 2, 3, 0, 3, 1, 0, 0, 2, 1, 7, 9, 8, 6, 4, 7, 5, 4, 8, 4, 9, 8,\n",
       "         7, 4, 9, 7, 4, 8],\n",
       "        [0, 0, 0, 1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5, 6, 6, 6, 7, 7, 7,\n",
       "         8, 8, 8, 9, 9, 9]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_index\n",
    "# you can see that there is no connection between different events"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0f5bd0-9d64-45e4-9d23-ebee4e53b55d",
   "metadata": {},
   "source": [
    "> **Note (`loop=False`)**: This disables self-loops in the kNN graph.  \n",
    "> With `loop=False`, edges like `i → i` are **not** added (a node is not considered its own neighbor).  \n",
    "> With `loop=True`, self-loop edges `i → i` **are included**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3da1a12-c12f-4d2f-83ef-c022a458414e",
   "metadata": {},
   "source": [
    "## Apply EdgeConv (one layer)\n",
    "\n",
    "We now have:\n",
    "- `x` with shape `[N, F]` (node features)\n",
    "- `edge_index` with shape `[2, E]` (kNN graph)\n",
    "\n",
    "EdgeConv needs an MLP `h_θ` that maps the concatenated vector  \n",
    "`[x_i, x_j - x_i]` (dimension `2F`) into an output embedding.\n",
    "\n",
    "Then it aggregates messages from neighbors (here: `max`) to produce `x_out`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24b58d39-d591-4172-9c74-84f386a88019",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -0.1572,  -1.1941, -10.0239,  -0.5515,  -0.2864,   1.2036,   0.2426,\n",
       "           0.3425],\n",
       "        [  6.5740,   3.3514,   3.4227,   2.1173,  -0.5528,  -0.0833,   0.5151,\n",
       "           0.0869],\n",
       "        [  3.7905,  -6.8601,  -0.0668,  -0.9295,   1.4618,  -0.7746,   0.1659,\n",
       "           0.3784],\n",
       "        [  1.5559,  -2.7138,  -5.7097,  -0.6423,   1.3420,  -0.7579,   1.2664,\n",
       "          -0.3835],\n",
       "        [ -3.6128,   1.0768,   5.0375,  -0.6368,   0.1879,  -0.9061,  -0.1070,\n",
       "          -0.6018],\n",
       "        [ -6.1118,   8.2047,  -6.6751,  -2.0629,  -0.2136,   0.1861,  -0.3162,\n",
       "           0.2089],\n",
       "        [ -0.9872,   2.5065,  -6.6366,  -3.0602,   0.6658,   0.2832,   0.2519,\n",
       "          -1.9083],\n",
       "        [ -4.6310,  -0.3009,   5.3977,   0.9575,  -1.7559,  -0.1788,  -0.5045,\n",
       "           1.0550],\n",
       "        [ -0.0400,  -3.3818,   4.0182,   1.8160,   0.0778,  -0.5094,  -0.0233,\n",
       "           0.2756],\n",
       "        [ -4.3483,   0.6645,   8.6566,   0.0539,   0.7440,   0.1583,  -1.3908,\n",
       "          -0.5963]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a70fdec6-d0d9-4abe-9d85-360568ad5680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F = 8\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import EdgeConv\n",
    "\n",
    "F = x.size(1) \n",
    "print(\"F =\", F)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81992139-5c2b-4380-9760-7e01c1125a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_out shape: torch.Size([10, 256])\n",
      "First node before:\n",
      " tensor([ -0.1572,  -1.1941, -10.0239,  -0.5515,  -0.2864,   1.2036,   0.2426,\n",
      "          0.3425])\n",
      "First node after:\n",
      " tensor([-1.0370e+00,  5.4676e+00, -2.6796e+00, -3.2898e-03,  2.0559e+00,\n",
      "         1.0472e+00, -3.2227e+00, -2.0603e+00, -2.3729e-01,  8.9579e-01,\n",
      "        -1.2599e+00,  4.1485e+00,  1.2905e+00,  4.1283e+00,  3.2679e+00,\n",
      "        -1.1494e-01,  2.7642e+00,  7.1270e-01, -8.6909e-03,  3.5283e+00,\n",
      "         1.2398e+00, -2.4999e+00,  3.7444e+00,  1.7295e+00, -6.8036e-01,\n",
      "         2.5756e+00, -5.6287e+00,  7.7296e-01, -1.0315e-01,  1.7377e+00,\n",
      "        -3.1972e+00, -2.2684e+00,  1.7628e+00, -4.6151e-01,  1.3792e-01,\n",
      "         2.3389e+00,  2.6050e+00, -1.5212e+00,  2.5155e+00, -5.7116e-02,\n",
      "         2.0707e+00, -7.3036e-01, -4.2728e+00,  4.3175e-01, -3.0296e+00,\n",
      "         4.9928e-02, -1.1414e-01,  9.0156e-01, -5.2839e+00,  3.4741e+00,\n",
      "        -1.2232e+00, -1.7794e+00, -3.2967e+00, -2.2214e+00,  4.3977e+00,\n",
      "        -2.3234e+00, -3.7641e-01, -1.6141e+00, -4.7926e+00,  4.8979e+00,\n",
      "        -2.3103e+00, -6.3833e-01,  3.4820e+00,  1.2314e+00, -8.6571e-01,\n",
      "        -8.3437e-01, -1.5759e+00, -4.2907e-01, -1.2057e+00, -1.8743e+00,\n",
      "         1.5159e+00,  2.4138e+00,  3.6309e+00,  2.0294e+00, -4.3534e+00,\n",
      "         2.8028e+00,  4.1170e+00,  1.1983e+00,  2.1391e+00,  1.5155e+00,\n",
      "        -1.2429e-01, -2.7904e-01,  1.2460e+00,  1.5332e+00, -3.6524e+00,\n",
      "        -2.6913e+00, -8.8860e-01,  2.8392e+00, -5.8580e-02, -3.3887e+00,\n",
      "         3.2537e-01, -2.2077e+00, -2.9998e+00,  4.1209e+00, -3.3929e+00,\n",
      "         4.6905e+00, -1.8514e+00, -4.0241e+00, -1.0361e+00,  2.0608e+00,\n",
      "        -1.8634e+00, -1.5681e+00, -2.9581e+00, -1.0893e-01, -8.4855e-01,\n",
      "         7.2666e-01, -3.7243e+00,  1.5227e+00, -1.3323e+00,  2.9306e+00,\n",
      "         1.8236e-01, -1.4160e+00, -1.4579e+00,  1.2961e+00,  1.8969e+00,\n",
      "        -1.1704e+00,  2.5029e+00, -1.0858e+00,  8.9237e-01, -3.7638e+00,\n",
      "         2.2243e+00, -3.8585e-01,  1.9081e+00, -2.1142e-01,  2.9779e+00,\n",
      "        -5.9430e+00,  1.1780e+00, -2.3732e-01, -1.5423e+00, -2.0429e+00,\n",
      "         5.6927e-01, -5.3998e-01,  6.6490e-01, -1.7131e+00, -5.7794e-01,\n",
      "        -1.2602e+00,  6.6173e-01,  6.3655e+00,  4.2699e-01, -3.1206e+00,\n",
      "        -1.4069e+00, -1.0530e+00,  1.9282e+00, -3.0060e+00,  2.7126e+00,\n",
      "        -2.6729e+00,  2.1484e+00, -2.3434e-01,  4.7200e+00,  3.3162e+00,\n",
      "        -5.3923e+00, -4.6581e-01, -2.0083e+00,  3.5989e+00,  4.8838e-01,\n",
      "         4.1366e+00, -6.3402e+00,  1.7422e+00,  1.0290e+00, -3.1244e+00,\n",
      "        -2.5491e+00, -3.3008e-01,  2.7926e+00,  3.0954e-01, -1.8687e-02,\n",
      "         1.7335e-01, -3.6341e+00,  2.1742e+00, -3.2403e+00,  1.1975e+00,\n",
      "        -2.1225e+00,  3.1212e-01,  3.9528e+00,  3.3961e+00,  1.2320e+00,\n",
      "        -2.1849e+00,  3.7669e+00, -1.4297e+00,  3.8170e+00,  4.5115e-01,\n",
      "        -3.6002e+00, -2.2476e-01, -8.6202e-01, -8.9382e-01, -5.4043e+00,\n",
      "        -2.8809e+00,  1.9168e+00,  1.4193e-01,  1.0130e-01, -5.1299e+00,\n",
      "        -1.1028e+00, -1.2970e+00,  9.4792e-01, -5.8015e-01,  6.3522e-02,\n",
      "        -1.3293e+00, -1.5633e+00,  4.6084e-01,  8.1665e-01,  2.1043e+00,\n",
      "        -5.7662e+00, -1.8959e-02, -4.1323e+00,  1.9321e+00,  2.0451e+00,\n",
      "         4.7875e-01, -3.1974e+00,  1.9608e+00,  3.2542e+00,  6.3007e-01,\n",
      "        -3.3941e+00, -8.2774e-01,  3.8140e+00,  2.3477e-01, -6.0533e-01,\n",
      "         4.3968e+00,  5.9028e+00, -9.0632e-01,  6.4912e-01,  1.1067e+00,\n",
      "        -2.3353e-01,  1.6182e+00,  4.5965e+00,  1.4000e+00,  1.0056e+00,\n",
      "         2.9898e+00, -3.8987e-01, -2.3305e+00,  9.3628e-01,  2.3234e+00,\n",
      "        -5.7373e+00,  1.5394e+00,  1.0741e+00, -3.3337e+00,  1.8388e+00,\n",
      "         2.3812e+00, -2.7401e+00,  2.4246e+00, -1.6837e+00,  2.7239e+00,\n",
      "         4.4581e+00,  4.6498e+00, -4.7062e-01, -4.0238e-01, -3.2160e+00,\n",
      "        -1.6159e-01, -3.0931e+00, -3.3028e+00,  5.0292e+00, -1.7498e-01,\n",
      "        -5.0308e-01, -2.0070e+00,  2.9522e+00,  2.5676e+00,  1.4203e-01,\n",
      "        -3.0608e+00], grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# EdgeConv uses concat([x_i, x_j - x_i]) -> input dim = 2F\n",
    "mlp = nn.Sequential(\n",
    "    nn.Linear(2*F, 32),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(32, 256)   # used in the article\n",
    ")\n",
    "# PyTorch's default initialization is used here.\n",
    "\n",
    "\n",
    "conv = EdgeConv(nn=mlp, aggr=\"sum\")   # try \"sum\" later\n",
    "x_out = conv(x, edge_index)\n",
    "\n",
    "print(\"x_out shape:\", x_out.shape)    # [N, 256]\n",
    "print(\"First node before:\\n\", x[0])\n",
    "print(\"First node after:\\n\", x_out[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "99df6a4d-d287-4a4c-b328-e09be32dc97c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 8])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12d14cf0-e390-4da2-bc35-b3819395097b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 256])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "99c6fbe7-46bb-4e96-b5b1-af6859b89700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target counts per node: [3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n"
     ]
    }
   ],
   "source": [
    "# Each node should appear ~k times as a target (second row), because edges are directed.\n",
    "targets = edge_index[1]\n",
    "counts = torch.bincount(targets, minlength=x.size(0))\n",
    "\n",
    "print(\"Target counts per node:\", counts.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58eb00f6-a8fe-4321-8fc6-68957411a8c7",
   "metadata": {},
   "source": [
    "# DynEdgeConv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df659227-3ecd-4378-866a-1fb8bef161bb",
   "metadata": {},
   "source": [
    "### What is a `LightningModule`?\n",
    "\n",
    "A `LightningModule` is the core class in **PyTorch Lightning**. It is a structured way to define a model *and* the training logic in one place, so you don’t have to write the full PyTorch training loop manually.\n",
    "\n",
    "Typically, a `LightningModule` contains:\n",
    "\n",
    "- **`forward()`**: how the model produces outputs from inputs  \n",
    "- **`training_step(batch, batch_idx)`**: how to compute the training loss for one batch  \n",
    "- **`validation_step(...)` / `test_step(...)`**: evaluation logic  \n",
    "- **`configure_optimizers()`**: how to set up the optimizer (and optional schedulers)\n",
    "\n",
    "In short:  \n",
    "**PyTorch** gives you the building blocks,  \n",
    "**PyTorch Lightning** (via `LightningModule`) standardizes the training loop and organizes your code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf73fe78-95e5-4dac-810d-71ec2ec216f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## this is from GraphNet source codes\n",
    "\n",
    "\n",
    "from typing import Any, Callable, Optional, Sequence, Union\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch_geometric.nn import EdgeConv\n",
    "from torch_geometric.nn.pool import knn_graph\n",
    "from torch_geometric.typing import Adj\n",
    "from pytorch_lightning import LightningModule\n",
    "\n",
    "\n",
    "class DynEdgeConv(EdgeConv, LightningModule):\n",
    "    \"\"\"Dynamical edge convolution layer.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        nn: Callable,\n",
    "        aggr: str = \"add\", # sum is used in the article\n",
    "        nb_neighbors: int = 8, # 8 is used in the article\n",
    "        features_subset: Optional[Union[Sequence[int], slice]] = None,\n",
    "        **kwargs: Any,\n",
    "    ):\n",
    "        \"\"\"Construct `DynEdgeConv`.\n",
    "\n",
    "        Args:\n",
    "            nn: The MLP/torch.Module to be used within the `EdgeConv`.\n",
    "            aggr: Aggregation method to be used with `EdgeConv`.\n",
    "            nb_neighbors: Number of neighbours to be clustered after the\n",
    "                `EdgeConv` operation.\n",
    "            features_subset: Subset of features in `Data.x` that should be used\n",
    "                when dynamically performing the new graph clustering after the\n",
    "                `EdgeConv` operation. Defaults to all features.  \n",
    "            **kwargs: Additional features to be passed to `EdgeConv`.\n",
    "        \"\"\"\n",
    "        # Check(s)\n",
    "        if features_subset is None:\n",
    "            features_subset = slice(None)  # Use all features\n",
    "        assert isinstance(features_subset, (list, slice))\n",
    "\n",
    "        # Base class constructor\n",
    "        super().__init__(nn=nn, aggr=aggr, **kwargs)\n",
    "\n",
    "        # Additional member variables\n",
    "        self.nb_neighbors = nb_neighbors\n",
    "        self.features_subset = features_subset\n",
    "\n",
    "    def forward(\n",
    "        self, x: Tensor, edge_index: Adj, batch: Optional[Tensor] = None\n",
    "    ) -> Tensor:\n",
    "        \"\"\"Forward pass.\"\"\"\n",
    "        # Standard EdgeConv forward pass\n",
    "        x = super().forward(x, edge_index)\n",
    "\n",
    "        # compute new adjacency\n",
    "        edge_index = knn_graph(\n",
    "            x=x[:, self.features_subset],\n",
    "            k=self.nb_neighbors,\n",
    "            batch=batch,\n",
    "        ).to(self.device)\n",
    "\n",
    "        return x, edge_index\n",
    "\n",
    "## only forward? should i add other stuff?\n",
    "\n",
    "# init ederken features_subset'I None birak. Cunku zaten ilk layerda 3 olmasini onceden hesapliyosun. Burada, ikinci (ve sonraki) layerlar icin\n",
    "# veriliyor bu parametre.\n",
    "# nb_neighbors: bunu sanirim makalede hep 8 secmisler. Ama sen kendin karar ver buna. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6e417a9a-8169-41e7-86eb-f9414e1ef04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fake data: 2 event, 5 node each.\n",
    "n0, n1 = 5, 5\n",
    "n = n0 + n1\n",
    "\n",
    "batch = torch.tensor([0]*n0 + [1]*n1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "232fe94b-7893-4f5b-bd3f-1a50cf386981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch\n",
    "# indexes: pulse id\n",
    "# Not: Bu “pulse id” sadece o mini-batch içinde geçerli (dataset genelinde kalıcı bir ID değil)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9668f007-49f4-4edf-b48a-e20cc2ff98f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Node features: let's create [N, 8] : pmt_x, pmt_y, pmt_z, pmt_i, pmt_j, pmt_k, q, t (i, j, k: angle; x, y, z: position)\n",
    "# First 3 features = \"position\" (used for kNN)\n",
    "pos = torch.randn(N, 3) * 5.0\n",
    "other_5 = torch.randn(N, 5)\n",
    "x = torch.cat([pos, other_5], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d6644880-f550-45fb-a832-27083fbbcd6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.3131, -5.2460,  4.5672],\n",
       "        [ 4.9336, -4.5426,  3.3155],\n",
       "        [-4.2067,  3.4617,  3.2696],\n",
       "        [ 0.3581, -5.7185,  0.3676],\n",
       "        [-0.9504, -2.5171,  1.5353],\n",
       "        [ 1.1992, -1.7472,  4.5736],\n",
       "        [-4.4386, -1.0320, -5.0398],\n",
       "        [ 1.5857, -3.4883, -3.0318],\n",
       "        [-3.5653, -7.1069, -0.4550],\n",
       "        [-3.3526,  3.7619, -7.6058]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7a4f33d9-82ba-41ec-8534-02ac152a96aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1102, -1.0765,  1.2198, -0.3551, -1.3987],\n",
       "        [ 0.5555, -1.7933,  1.4585, -0.2492, -0.7961],\n",
       "        [-1.5236,  1.3001, -0.1664, -1.5490, -0.2919],\n",
       "        [-0.0208, -0.3597,  0.0589,  1.0251,  0.1441],\n",
       "        [-0.6544, -0.2587,  0.0216, -1.5524, -0.4753],\n",
       "        [ 0.9003,  1.8899,  1.1911,  1.4694, -0.1391],\n",
       "        [-1.9213, -0.3719,  2.1403, -0.0090,  0.7390],\n",
       "        [ 0.5260, -1.5670, -0.4099, -1.9789,  0.0352],\n",
       "        [ 0.5567, -0.1976,  0.4111,  0.6739, -2.0867],\n",
       "        [-1.2404,  0.1228,  0.4560, -0.8187, -1.3543]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "other_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "50fd9b45-9698-4956-89ac-1b730a881f8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.3131, -5.2460,  4.5672, -0.1102, -1.0765,  1.2198, -0.3551, -1.3987],\n",
       "        [ 4.9336, -4.5426,  3.3155,  0.5555, -1.7933,  1.4585, -0.2492, -0.7961],\n",
       "        [-4.2067,  3.4617,  3.2696, -1.5236,  1.3001, -0.1664, -1.5490, -0.2919],\n",
       "        [ 0.3581, -5.7185,  0.3676, -0.0208, -0.3597,  0.0589,  1.0251,  0.1441],\n",
       "        [-0.9504, -2.5171,  1.5353, -0.6544, -0.2587,  0.0216, -1.5524, -0.4753],\n",
       "        [ 1.1992, -1.7472,  4.5736,  0.9003,  1.8899,  1.1911,  1.4694, -0.1391],\n",
       "        [-4.4386, -1.0320, -5.0398, -1.9213, -0.3719,  2.1403, -0.0090,  0.7390],\n",
       "        [ 1.5857, -3.4883, -3.0318,  0.5260, -1.5670, -0.4099, -1.9789,  0.0352],\n",
       "        [-3.5653, -7.1069, -0.4550,  0.5567, -0.1976,  0.4111,  0.6739, -2.0867],\n",
       "        [-3.3526,  3.7619, -7.6058, -1.2404,  0.1228,  0.4560, -0.8187, -1.3543]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "642ad265-aec8-46ff-a77d-5ad4d915d0d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape: torch.Size([10, 8])\n",
      "batch: tensor([0, 0, 0, 0, 0, 1, 1, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "print(\"x shape:\", x.shape)  # [10, 8] : 10 node (for 2 event), 6 features\n",
    "print(\"batch:\", batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9dd25012-2f7a-432e-9ffa-d10cb4376900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edge_index0 shape: torch.Size([2, 30])\n"
     ]
    }
   ],
   "source": [
    "# 3) Initial adjacency (edge_index) \n",
    "edge_index0 = knn_graph(x=pos, k=3, batch=batch, loop=False)\n",
    "print(\"edge_index0 shape:\", edge_index0.shape)  # [2, n*k] ~ [2, 30] : 10 nodes each having 3 neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cef0b54b-866b-4761-bc93-c84dfd5837e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edge_index0:\n",
      " tensor([[4, 3, 1, 3, 0, 4, 4, 0, 3, 4, 0, 1, 3, 0, 1, 7, 8, 6, 9, 7, 8, 8, 6, 5,\n",
      "         7, 6, 5, 6, 7, 8],\n",
      "        [0, 0, 0, 1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5, 6, 6, 6, 7, 7, 7,\n",
      "         8, 8, 8, 9, 9, 9]])\n"
     ]
    }
   ],
   "source": [
    "print(\"edge_index0:\\n\", edge_index0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2680edb8-bab1-4d11-a349-f4029f61c48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input size of the mlp = 2*F\n",
    "mlp = nn.Sequential(\n",
    "    nn.Linear(16, 32),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(32, 256)   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c7a7498d-750d-47d9-8daf-f0c56e478a93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=16, out_features=32, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=32, out_features=256, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "72413ddd-89fb-446c-a2f6-f43dac5f8270",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = DynEdgeConv(\n",
    "    nn=mlp,\n",
    "    nb_neighbors=3,                \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e82c22b4-eab1-4199-91ef-184c00e21237",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, edge_index1 = layer(x, edge_index0, batch=batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8302e667-f4f7-4792-b1e9-3dbaddca807f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.1364, -0.8595, -0.5129,  ..., -0.4237, -0.4554, -1.7924],\n",
       "        [-1.7836, -0.6169, -0.9150,  ...,  1.1913,  1.2121, -3.4018],\n",
       "        [-0.1512,  0.9915,  1.5075,  ..., -1.6531, -1.6588,  0.4486],\n",
       "        ...,\n",
       "        [-2.1455, -2.0212, -1.3974,  ..., -0.6470, -0.2686, -1.9106],\n",
       "        [-2.9431, -2.2061,  0.2430,  ..., -2.6065, -0.0694, -0.5376],\n",
       "        [-4.3823, -1.0552, -1.1999,  ..., -1.6722, -2.5916,  0.7589]],\n",
       "       grad_fn=<ScatterAddBackward0>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "42c00381-c67e-462f-958a-351d1355f5e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- AFTER DynEdgeConv ---\n",
      "x1 shape: torch.Size([10, 256])\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- AFTER DynEdgeConv ---\")\n",
    "print(\"x1 shape:\", x1.shape)               # [n, out_dim] = [10, 256]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5db6af90-87b1-4330-ac2a-6fd1845eeac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- AFTER DynEdgeConv ---\n",
      "edge_index1 shape: torch.Size([2, 30])\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- AFTER DynEdgeConv ---\")\n",
    "print(\"edge_index1 shape:\", edge_index1.shape)  # [2, n*k] ~ [2, 30]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "718f1457-daa1-4c1a-a5f5-9459559e0096",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4, 3, 1, 3, 4, 0, 4, 0, 3, 4, 0, 1, 0, 3, 1, 7, 6, 8, 9, 7, 8, 6, 9, 8,\n",
       "         6, 7, 9, 6, 7, 8],\n",
       "        [0, 0, 0, 1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5, 6, 6, 6, 7, 7, 7,\n",
       "         8, 8, 8, 9, 9, 9]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_index1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a453b946-2da0-4793-8709-fb3c738c341c",
   "metadata": {},
   "source": [
    "PyTorch’ta bir layer/modeli `layer(...)` diye çağırdığında aslında **`__call__`** çalışır. Bu `__call__`, senin yazdığın **`forward(...)`** metodunu çağırır. Ayrıca `__call__` araya PyTorch’un mekaniklerini koyar: autograd grafını kurar (gradient’ler için), `training/eval` modunu uygular (dropout/batchnorm gibi), forward/backward hook’ları çalıştırır ve (varsa) mixed precision/autocast gibi şeyleri yönetir. Kısaca: **`forward` hesabın tarifi**, **`__call__` o hesabı PyTorch kurallarıyla çalıştıran mekanizma**.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (graphnet_env)",
   "language": "python",
   "name": "graphnet_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
