===== SLURM INFO =====
JOBID: 22724716
NODELIST: fc10413
CPUS_PER_TASK: 12
GPUS_ON_NODE: 1
SUBMIT_DIR: /project/6061446/kbas/Graphnet-Applications/Training/Combined_EventPulseSeries_nonoise/initiative7
======================
===== SCONTROL (Req/Alloc) =====
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=fc10413
   ReqTRES=cpu=12,mem=48G,node=1,billing=12200,gres/gpu=1,gres/gpu:h100=1
   AllocTRES=cpu=12,mem=48G,node=1,billing=12200,gres/gpu=1,gres/gpu:h100=1
================================
The following modules were not unloaded:
  (Use "module --force purge" to unload all):

  1) CCconfig        6)  ucx/1.14.1         11) flexiblas/3.3.1
  2) gentoo/2023     7)  libfabric/1.18.0   12) aocl-blas/5.1
  3) gcccore/.12.3   8)  pmix/4.2.4         13) aocl-lapack/5.1
  4) gcc/12.3        9)  ucc/1.2.0          14) StdEnv/2023
  5) hwloc/2.9.1     10) openmpi/4.1.5
===== ENV SETUP =====
PWD: /project/def-nahee/kbas/pone_offline
Activating venv: /project/def-nahee/kbas/pone_offline/graphnet_env/bin/activate
Python: /project/6061446/kbas/pone_offline/graphnet_env/bin/python3
sys.executable = /project/6061446/kbas/pone_offline/graphnet_env/bin/python3
torch: 2.6.0
cuda available: True
cuda device: NVIDIA H100 80GB HBM3
===== GPU INFO =====
Thu Feb 12 08:59:07 2026       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 580.65.06              Driver Version: 580.65.06      CUDA Version: 13.0     |
+-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA H100 80GB HBM3          On  |   00000000:4C:00.0 Off |                    0 |
| N/A   21C    P0             66W /  700W |       0MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+

+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
====================
===== RUN =====

========== CONFIG ==========
seed: 20260202
train_path: /project/def-nahee/kbas/POM_Response_Parquet/merged/train_reindexed
val_path: /project/def-nahee/kbas/POM_Response_Parquet/merged/val_reindexed
test_path: /project/def-nahee/kbas/POM_Response_Parquet/merged/test_reindexed
pulsemaps: features
truth_table: truth
features: ('pmt_x', 'pmt_y', 'pmt_z', 'dom_time', 'charge')
truth_all: ('azimuth', 'zenith', 'energy')
batch_size: 256
num_workers: 8
multiprocessing_context: spawn
persistent_workers: True
pin_memory: True
max_epochs: 30
early_stopping_patience: 5
base_lr: 1e-05
peak_lr: 0.001
accumulate_grad_batches: 4
nb_neighbours: 8
global_pooling_schemes: ('min', 'max', 'mean', 'sum')
add_global_variables_after_pooling: True
add_norm_layer: False
skip_readout: False
transform_support: (10.0, 100000000.0)
save_dir: /project/6061446/kbas/Graphnet-Applications/Training/Combined_EventPulseSeries_nonoise/initiative7
metrics_name: metrics.csv
test_csv_name: test_predictions.csv
============================

[Data] Building data_representation (KNNGraph + robust scaling)
[1;34mgraphnet[0m [MainProcess] [32mINFO    [0m 2026-02-12 09:02:13 - PONE.__init__ - Writing log to [1mlogs/graphnet_20260212-090213.log[0m
[Data] Creating ParquetDataset(s)
[Data] Creating DataLoader(s)
[Data] len(train_loader) = 1256 batches/epoch (drop_last=True)
[Data] len(val_loader)   = 156 batches/epoch
[Data] len(test_loader)  = 162 batches
[Sanity] azimuth range: 0.022..6.274
[Sanity] zenith  range: 0.059..3.082
[Sanity] energy  range: 1.012e+02..3.088e+06
[rank: 0] Seed set to 20260202

[Run=energy] torch.cuda.is_available() = True
[Run=energy] GPU = NVIDIA H100 80GB HBM3
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
/project/6061446/kbas/pone_offline/graphnet_env/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:76: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default
You are using a CUDA device ('NVIDIA H100 80GB HBM3') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
[Time] Fit start: 2026-02-12T09:04:17 | CSV: /project/6061446/kbas/Graphnet-Applications/Training/Combined_EventPulseSeries_nonoise/initiative7/energy/epoch_time.csv

  | Name                 | Type       | Params | Mode 
------------------------------------------------------------
0 | _tasks               | ModuleList | 129    | train
1 | _data_representation | KNNGraph   | 0      | train
2 | backbone             | DynEdge    | 1.4 M  | train
------------------------------------------------------------
1.4 M     Trainable params
0         Non-trainable params
1.4 M     Total params
5.501     Total estimated model params size (MB)
36        Modules in train mode
0         Modules in eval mode
SLURM auto-requeueing enabled. Setting signal handlers.
Metric val_loss improved. New best score: 0.131 | epoch: 0
[1;34mgraphnet[0m [MainProcess] [32mINFO    [0m 2026-02-12 09:25:40 - StandardModel.save_state_dict - Model state_dict saved to /project/6061446/kbas/Graphnet-Applications/Training/Combined_EventPulseSeries_nonoise/initiative7/energy/best_model.pth[0m
[Time] Epoch 0 duration = 20.46 min | elapsed = 21.37 min | now = 2026-02-12T09:25:40
Metric val_loss improved by 0.009 >= min_delta = 0.0. New best score: 0.123 | epoch: 1
[1;34mgraphnet[0m [MainProcess] [32mINFO    [0m 2026-02-12 09:45:59 - StandardModel.save_state_dict - Model state_dict saved to /project/6061446/kbas/Graphnet-Applications/Training/Combined_EventPulseSeries_nonoise/initiative7/energy/best_model.pth[0m
[Time] Epoch 1 duration = 20.32 min | elapsed = 41.70 min | now = 2026-02-12T09:45:59
Metric val_loss improved by 0.010 >= min_delta = 0.0. New best score: 0.113 | epoch: 2
[1;34mgraphnet[0m [MainProcess] [32mINFO    [0m 2026-02-12 10:06:14 - StandardModel.save_state_dict - Model state_dict saved to /project/6061446/kbas/Graphnet-Applications/Training/Combined_EventPulseSeries_nonoise/initiative7/energy/best_model.pth[0m
[Time] Epoch 2 duration = 20.25 min | elapsed = 61.95 min | now = 2026-02-12T10:06:14
srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
slurmstepd: error: *** STEP 22724716.0 ON fc10413 CANCELLED AT 2026-02-12T10:14:40 ***
slurmstepd: error: *** JOB 22724716 ON fc10413 CANCELLED AT 2026-02-12T10:14:40 ***
[rank: 0] Received SIGTERM: 15
Bypassing SIGTERM: 15
