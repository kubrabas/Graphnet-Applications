epoch,train_loss,val_loss
0,,0.05139490883806799
1,0.8808927371162713,-0.23195598039749357
2,-0.11217089861329134,-0.3435652997038617
3,-0.2832734651841312,-0.3689045994669321
4,-0.36013412628891384,-0.4322947467352303
5,-0.39961571871195295,-0.4439127958682748
6,-0.4376542183051637,-0.46270401355992713
7,-0.46262705231678547,-0.499630196883199
8,-0.48669819381013274,-0.5109753925378832
9,-0.5124302002701874,-0.5255462258269281
10,-0.527560536687581,-0.5004267273765264
11,-0.5400672482759293,-0.5415539079962299
12,-0.5528946170883365,-0.5499420419877855
13,-0.56779962356708,-0.5463585475368097
14,-0.5760181059574488,-0.5506508690247459
15,-0.5887999273596085,-0.5648519451498851
16,-0.5976070044951841,-0.5610483261537759
17,-0.6093116352227977,-0.5797690547438135
18,-0.6183422726243016,-0.5759123213317395
19,-0.6286789130502228,-0.5778337528326042
20,-0.6379583196553171,-0.5703095543577575
21,-0.6501098053096002,-0.5845673945589432
22,-0.6598505714920145,-0.5896170700960202
23,-0.6723997305043433,-0.5854907876875856
24,-0.6835669384091182,-0.5869988860508926
25,-0.698862943798797,-0.590945774784976
26,-0.7124367256542111,-0.589523782178798
27,-0.7256338123352898,-0.5895179772191489
28,-0.7391679008082241,-0.5825805568352523
29,-0.7535436852606744,-0.5828006154866868
