===== SLURM INFO =====
JOBID: 22732569
NODELIST: fc10406
CPUS_PER_TASK: 12
GPUS_ON_NODE: 1
SUBMIT_DIR: /project/6061446/kbas/Graphnet-Applications/Training/Combined_EventPulseSeries_nonoise/initiative8
======================
===== SCONTROL (Req/Alloc) =====
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=fc10406
   ReqTRES=cpu=12,mem=48G,node=1,billing=12200,gres/gpu=1,gres/gpu:h100=1
   AllocTRES=cpu=12,mem=48G,node=1,billing=12200,gres/gpu=1,gres/gpu:h100=1
================================
The following modules were not unloaded:
  (Use "module --force purge" to unload all):

  1) CCconfig        6)  ucx/1.14.1         11) flexiblas/3.3.1
  2) gentoo/2023     7)  libfabric/1.18.0   12) aocl-blas/5.1
  3) gcccore/.12.3   8)  pmix/4.2.4         13) aocl-lapack/5.1
  4) gcc/12.3        9)  ucc/1.2.0          14) StdEnv/2023
  5) hwloc/2.9.1     10) openmpi/4.1.5
===== ENV SETUP =====
PWD: /project/def-nahee/kbas/pone_offline
Activating venv: /project/def-nahee/kbas/pone_offline/graphnet_env/bin/activate
Python: /project/6061446/kbas/pone_offline/graphnet_env/bin/python3
sys.executable = /project/6061446/kbas/pone_offline/graphnet_env/bin/python3
torch: 2.6.0
cuda available: True
cuda device: NVIDIA H100 80GB HBM3
===== GPU INFO =====
Thu Feb 12 10:31:08 2026       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 580.65.06              Driver Version: 580.65.06      CUDA Version: 13.0     |
+-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA H100 80GB HBM3          On  |   00000000:46:00.0 Off |                    0 |
| N/A   24C    P0             66W /  700W |       0MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+

+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
====================
===== RUN =====

========== CONFIG ==========
seed: 20260202
train_path: /project/def-nahee/kbas/POM_Response_Parquet/merged/train_reindexed
val_path: /project/def-nahee/kbas/POM_Response_Parquet/merged/val_reindexed
test_path: /project/def-nahee/kbas/POM_Response_Parquet/merged/test_reindexed
pulsemaps: features
truth_table: truth
features: ('pmt_x', 'pmt_y', 'pmt_z', 'dom_time', 'charge')
truth_all: ('azimuth', 'zenith', 'energy')
batch_size: 256
num_workers: 8
multiprocessing_context: spawn
persistent_workers: True
pin_memory: True
max_epochs: 3
early_stopping_patience: 5
base_lr: 1e-05
peak_lr: 0.001
accumulate_grad_batches: 4
nb_neighbours: 8
global_pooling_schemes: ('min', 'max', 'mean', 'sum')
add_global_variables_after_pooling: True
add_norm_layer: False
skip_readout: False
transform_support: (10.0, 100000000.0)
save_dir: /project/6061446/kbas/Graphnet-Applications/Training/Combined_EventPulseSeries_nonoise/initiative8
metrics_name: metrics.csv
test_csv_name: test_predictions.csv
resources_and_time_csv_name: resources_and_time.csv
============================

[Data] Building data_representation (KNNGraph + robust scaling)
[1;34mgraphnet[0m [MainProcess] [32mINFO    [0m 2026-02-12 10:34:38 - PONE.__init__ - Writing log to [1mlogs/graphnet_20260212-103438.log[0m
[Data] Creating ParquetDataset(s)
[Data] Creating DataLoader(s)
[Data] len(train_loader) = 1256 batches/epoch (drop_last=True)
[Data] len(val_loader)   = 156 batches/epoch
[Data] len(test_loader)  = 162 batches
[Sanity] azimuth range: 0.011..6.257
[Sanity] zenith  range: 0.147..3.098
[Sanity] energy  range: 1.013e+02..7.212e+06
[rank: 0] Seed set to 20260202

[Run=energy] torch.cuda.is_available() = True
[Run=energy] GPU = NVIDIA H100 80GB HBM3
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
/project/6061446/kbas/pone_offline/graphnet_env/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:76: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default
You are using a CUDA device ('NVIDIA H100 80GB HBM3') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name                 | Type       | Params | Mode 
------------------------------------------------------------
0 | _tasks               | ModuleList | 129    | train
1 | _data_representation | KNNGraph   | 0      | train
2 | backbone             | DynEdge    | 1.4 M  | train
------------------------------------------------------------
1.4 M     Trainable params
0         Non-trainable params
1.4 M     Total params
5.501     Total estimated model params size (MB)
36        Modules in train mode
0         Modules in eval mode
SLURM auto-requeueing enabled. Setting signal handlers.
Metric val_loss improved. New best score: 0.128 | epoch: 0
[1;34mgraphnet[0m [MainProcess] [32mINFO    [0m 2026-02-12 10:57:06 - StandardModel.save_state_dict - Model state_dict saved to /project/6061446/kbas/Graphnet-Applications/Training/Combined_EventPulseSeries_nonoise/initiative8/energy/best_model.pth[0m
Metric val_loss improved by 0.012 >= min_delta = 0.0. New best score: 0.116 | epoch: 1
[1;34mgraphnet[0m [MainProcess] [32mINFO    [0m 2026-02-12 11:16:16 - StandardModel.save_state_dict - Model state_dict saved to /project/6061446/kbas/Graphnet-Applications/Training/Combined_EventPulseSeries_nonoise/initiative8/energy/best_model.pth[0m
Metric val_loss improved by 0.011 >= min_delta = 0.0. New best score: 0.105 | epoch: 2
[1;34mgraphnet[0m [MainProcess] [32mINFO    [0m 2026-02-12 11:35:17 - StandardModel.save_state_dict - Model state_dict saved to /project/6061446/kbas/Graphnet-Applications/Training/Combined_EventPulseSeries_nonoise/initiative8/energy/best_model.pth[0m
`Trainer.fit` stopped: `max_epochs=3` reached.
[Resources] Wrote /project/6061446/kbas/Graphnet-Applications/Training/Combined_EventPulseSeries_nonoise/initiative8/energy/resources_and_time.csv | last_epoch=2 | total=59.94 min
[Run=energy] best_model: /project/6061446/kbas/Graphnet-Applications/Training/Combined_EventPulseSeries_nonoise/initiative8/energy/best_model.pth
[Run=energy] config:     /project/6061446/kbas/Graphnet-Applications/Training/Combined_EventPulseSeries_nonoise/initiative8/energy/config.yml
[Run=energy] metrics:    /project/6061446/kbas/Graphnet-Applications/Training/Combined_EventPulseSeries_nonoise/initiative8/energy/metrics.csv
[Test=energy] Loaded best weights: /project/6061446/kbas/Graphnet-Applications/Training/Combined_EventPulseSeries_nonoise/initiative8/energy/best_model.pth
[Test=energy] batch 0/162 | resid mean=-0.041
[Test=energy] batch 20/162 | resid mean=-0.074
[Test=energy] batch 40/162 | resid mean=-0.088
[Test=energy] batch 60/162 | resid mean=-0.029
[Test=energy] batch 80/162 | resid mean=-0.064
[Test=energy] batch 100/162 | resid mean=-0.001
[Test=energy] batch 120/162 | resid mean=-0.018
[Test=energy] batch 140/162 | resid mean=-0.020
[Test=energy] batch 160/162 | resid mean=-0.020
[Test=energy] Wrote: /project/6061446/kbas/Graphnet-Applications/Training/Combined_EventPulseSeries_nonoise/initiative8/energy/test_predictions.csv | rows=41311
[Test=energy] residual_log10: p16=-0.4006, p50=0.0375, p84=0.3624, W=0.3815
[rank: 0] Seed set to 20260202

[Run=zenith] torch.cuda.is_available() = True
[Run=zenith] GPU = NVIDIA H100 80GB HBM3
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name                 | Type       | Params | Mode 
------------------------------------------------------------
0 | _tasks               | ModuleList | 258    | train
1 | _data_representation | KNNGraph   | 0      | eval 
2 | backbone             | DynEdge    | 1.4 M  | train
------------------------------------------------------------
1.4 M     Trainable params
0         Non-trainable params
1.4 M     Total params
5.502     Total estimated model params size (MB)
32        Modules in train mode
4         Modules in eval mode
SLURM auto-requeueing enabled. Setting signal handlers.
/project/6061446/kbas/pone_offline/graphnet_env/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:527: Found 4 module(s) in eval mode at the start of training. This may lead to unexpected behavior during training. If this is intentional, you can ignore this warning.
Metric val_loss improved. New best score: 0.349 | epoch: 0
[1;34mgraphnet[0m [MainProcess] [32mINFO    [0m 2026-02-12 12:16:56 - StandardModel.save_state_dict - Model state_dict saved to /project/6061446/kbas/Graphnet-Applications/Training/Combined_EventPulseSeries_nonoise/initiative8/zenith/best_model.pth[0m
Metric val_loss improved by 0.441 >= min_delta = 0.0. New best score: -0.093 | epoch: 1
[1;34mgraphnet[0m [MainProcess] [32mINFO    [0m 2026-02-12 12:36:09 - StandardModel.save_state_dict - Model state_dict saved to /project/6061446/kbas/Graphnet-Applications/Training/Combined_EventPulseSeries_nonoise/initiative8/zenith/best_model.pth[0m
Metric val_loss improved by 0.416 >= min_delta = 0.0. New best score: -0.508 | epoch: 2
[1;34mgraphnet[0m [MainProcess] [32mINFO    [0m 2026-02-12 12:55:28 - StandardModel.save_state_dict - Model state_dict saved to /project/6061446/kbas/Graphnet-Applications/Training/Combined_EventPulseSeries_nonoise/initiative8/zenith/best_model.pth[0m
`Trainer.fit` stopped: `max_epochs=3` reached.
[Resources] Wrote /project/6061446/kbas/Graphnet-Applications/Training/Combined_EventPulseSeries_nonoise/initiative8/zenith/resources_and_time.csv | last_epoch=2 | total=61.25 min
[Run=zenith] best_model: /project/6061446/kbas/Graphnet-Applications/Training/Combined_EventPulseSeries_nonoise/initiative8/zenith/best_model.pth
[Run=zenith] config:     /project/6061446/kbas/Graphnet-Applications/Training/Combined_EventPulseSeries_nonoise/initiative8/zenith/config.yml
[Run=zenith] metrics:    /project/6061446/kbas/Graphnet-Applications/Training/Combined_EventPulseSeries_nonoise/initiative8/zenith/metrics.csv
[Test=zenith] Loaded best weights: /project/6061446/kbas/Graphnet-Applications/Training/Combined_EventPulseSeries_nonoise/initiative8/zenith/best_model.pth
[Test=zenith] batch 0/162 | median_abs_error_deg=3.811
[Test=zenith] batch 50/162 | median_abs_error_deg=4.462
[Test=zenith] batch 100/162 | median_abs_error_deg=4.223
[Test=zenith] batch 150/162 | median_abs_error_deg=4.578
[Test=zenith] Wrote: /project/6061446/kbas/Graphnet-Applications/Training/Combined_EventPulseSeries_nonoise/initiative8/zenith/test_predictions.csv | rows=41311
[Test=zenith] abs_error_deg: p16=1.195, p50=4.355, p84=12.272 | kappa_mean=48.611
[rank: 0] Seed set to 20260202

[Run=azimuth] torch.cuda.is_available() = True
[Run=azimuth] GPU = NVIDIA H100 80GB HBM3
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name                 | Type       | Params | Mode 
------------------------------------------------------------
0 | _tasks               | ModuleList | 258    | train
1 | _data_representation | KNNGraph   | 0      | eval 
2 | backbone             | DynEdge    | 1.4 M  | train
------------------------------------------------------------
1.4 M     Trainable params
0         Non-trainable params
1.4 M     Total params
5.502     Total estimated model params size (MB)
32        Modules in train mode
4         Modules in eval mode
SLURM auto-requeueing enabled. Setting signal handlers.
