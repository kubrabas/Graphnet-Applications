epoch,train_loss,val_loss
0,,-0.0006042761785259668
1,0.6979274354201636,-0.29740132804463143
2,-0.16611236928543843,-0.29505556096858077
3,-0.31379599347661896,-0.35043352087892266
4,-0.36121167031616536,-0.38911336664723484
5,-0.37977248258513263,-0.43313871037727436
6,-0.41821860972999997,-0.4554202058883044
7,-0.4395280734328861,-0.45686451736735384
8,-0.4607214662351544,-0.48308888698852304
9,-0.4757200928160759,-0.48559768336289744
10,-0.4904802312414133,-0.48010228779512687
11,-0.4958899048624644,-0.501726132665434
12,-0.5102146748345643,-0.48809906893729427
13,-0.5309803873151865,-0.5325953273824542
14,-0.5584862872873709,-0.5216779276949818
15,-0.5727763394325318,-0.5583423843019419
16,-0.590785577570205,-0.5538939751686874
17,-0.6047837370224476,-0.5607986647330659
18,-0.6157359316719627,-0.5823171442739951
19,-0.6298854594051185,-0.582855620310453
20,-0.641472608504544,-0.5605728629560792
21,-0.6536344285996496,-0.579628940782438
22,-0.6672248924984044,-0.5805346230666112
23,-0.6811451257840476,-0.5845576770994837
24,-0.6951589451527009,-0.5859115022738287
25,-0.7113988446299038,-0.5833069965717144
26,-0.7274325728738191,-0.5833577231208156
27,-0.7450310023191021,-0.5785882222932189
28,-0.7614552999058252,-0.5715184224878442
29,-0.7772509237399663,-0.5764612296110544
